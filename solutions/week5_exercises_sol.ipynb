{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **DO NOT EDIT IF INSIDE course Github folder**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architectures and concepts\n",
    "\n",
    "Part 5.1: Convolutional neural networks<br>\n",
    "Part 5.2: Recurrent neural networks<br>\n",
    "Part 5.3: Transfer learning<br>\n",
    "Part 5.4: VAEs<br>\n",
    "Part 5.5: GANs\n",
    "\n",
    "\n",
    "[**Feedback**]((https://ulfaslak.com/vent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T06:48:16.271739Z",
     "start_time": "2020-02-26T06:48:16.129933Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import random, sys, io\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, MaxPooling2D, Softmax\n",
    "from keras.layers import Dense, Conv2D, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pen and paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get your intuition for computations on input data in CNNs fine-tuned, I have a few small quizzes for you. First, we'll consider the size of the parameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.1.1**: Imagine you have a CNN with just one convolutional layer with a single filter. All it does, is take an input image and produce an activation map. The dimensionality of the filter in your convolutional layer is $5 \\times 5 \\times 3$. How many weights (or *parameters*) are there in this model?\n",
    ">\n",
    "> *Hint*: Don't forget the bias!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T20:48:58.308126Z",
     "start_time": "2019-09-30T20:45:56.791Z"
    }
   },
   "outputs": [],
   "source": [
    "5 * 5 * 3 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the formula for computing the size of the activation map resulting from a convolution. \n",
    "If you have a filter that is $F$ wide, your input image is $W_0$ wide, you are padding the edges by\n",
    "$P$ pixels and your stride is $S$, the resulting image will have width/height:\n",
    "\n",
    "$$ W_1 = \\frac{W_0 - F + 2P}{S} + 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.1.2**: You input an image of dimensions $28 \\times 28 \\times 3$, use a padding of 2, a stride of 1,\n",
    "and then slide your $5 \\times 5 \\times 3$ filter across the image. What is the dimensionality of the resulting activation map?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T10:32:54.674134Z",
     "start_time": "2019-10-15T10:32:54.668976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(28 - 5 + 2 * 2) / 1 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.1.3**: Let's say you now want to use a stride of 2, instead of 1. What problem does this immediately cause?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing stride 2, we see that the number of convolutions is not an integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T20:48:58.310907Z",
     "start_time": "2019-09-30T20:46:34.584Z"
    }
   },
   "outputs": [],
   "source": [
    "(28 - 5 + 2*1) / 2 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of convolution has to be an integer, otherwise we have to have asymmetric padding, which is not very\n",
    "nice. To make it an integer, we can change the dimensinality of the filter, to an even number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T10:37:31.607220Z",
     "start_time": "2019-10-15T10:37:31.602170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(28 - 5 + 2*2) / 2 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Maxpooling* is a method used a lot in CNNs, which downsamples the size of an activation map. It is used primarily to reduce the amount of parameters and computations needed in the network, and to avoid overfitting. Here's an illustration of how it works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](http://cs231n.github.io/assets/cnn/maxpool.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In *Max*pooling, for each $2 \\times 2$ square in your activation map, you pick the largest value in that square. You do this independently for every depth slice in your activation map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In Keras, the dimension of data is a little different from what you may expect. The first index,\n",
    "indexes datapoints, the second and third are the dimensions of your images, and the last is number of channels. So if\n",
    "you have a batch of data containing 100 datapoints, each one an RGB image (so 3 channels: red, green, blue)\n",
    "with resolution $128 \\times 128$, then the dimensionality of your input data is (100, 128, 128, 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.1.4**: Given the activation map below, what is the corresponding activation map after maxpooling ($2 \\times 2$ filter, stride 2)? Run it through a Keras maxpooling layer (check out [the docs](https://keras.io/layers/pooling/)), and report the dimensionality.\n",
    ">\n",
    "> *Hint: In Keras, layers (e.g.* `MaxPooling2D` *or* `MaxPool2D`*) are classes. An instance of such a class (e.g.* `mypool = MaxPool2D()`*) acts like a function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T19:37:21.198895Z",
     "start_time": "2019-09-30T19:37:21.107703Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.random.random(size=(10, 28, 28, 1))  # Create 10 x 28 x 28 x 1 matrix of random numbers\n",
    "activation_map = keras.backend.variable(a)  # Load it as a Tensorflow variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'max_pooling2d_4/MaxPool:0' shape=(10, 14, 14, 1) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MaxPooling2D()\n",
    "m(activation_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNNs in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example sake, I have implemented a single conv. layer neural network Keras below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T19:57:40.146609Z",
     "start_time": "2019-09-30T19:57:40.141327Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=10, kernel_size=3, strides=(1, 1), padding='valid'),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercise you will use the MNIST dataset again. Here is **some code that prepares** `x_train` and `x_test`, and `y_train` and `y_test` for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T20:12:46.465418Z",
     "start_time": "2019-09-30T20:12:46.027204Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape data so it has a channel dimension\n",
    "rows, cols = x_train.shape[-2:]\n",
    "x_train = x_train.reshape(x_train.shape[0], rows, cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], rows, cols, 1)\n",
    "\n",
    "# Convert pixel intensities to values between 0 and 1\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "    \n",
    "# Convert target vectors to one-hot encoding\n",
    "num_classes = len(set(y_train))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.1.5**: Implement Nielsen's [last convolutional neural network](http://neuralnetworksanddeeplearning.com/chap6.html#exercise_683491)\n",
    "(the one with two convolutional layers and dropout), and score an accuracy higher than 98%. It doesn't have to be\n",
    "fully identical, but his solution is pretty great, so getting close is a cheap way to score a high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 30s 501us/step - loss: 0.3315 - accuracy: 0.8920 - val_loss: 0.0541 - val_accuracy: 0.9845\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 33s 554us/step - loss: 0.0975 - accuracy: 0.9708 - val_loss: 0.0374 - val_accuracy: 0.9892\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 34s 566us/step - loss: 0.0771 - accuracy: 0.9765 - val_loss: 0.0279 - val_accuracy: 0.9913\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 34s 563us/step - loss: 0.0655 - accuracy: 0.9805 - val_loss: 0.0260 - val_accuracy: 0.9916\n",
      "Epoch 5/12\n",
      "19712/60000 [========>.....................] - ETA: 22s - loss: 0.0540 - accuracy: 0.9833"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-63283dcc9964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=20, kernel_size=5, strides=(1, 1), padding='valid', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    Conv2D(filters=40, kernel_size=5, strides=(1, 1), padding='valid', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='relu'),\n",
    "    Softmax()\n",
    "])\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=12,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2: Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text prediction is a good place to start when learning about RNNs, because most of us humans have a pretty well\n",
    "optimized inner model for text prediction ourselves. We can, therefore, easily assess the performance of a neural\n",
    "network in executing this task.\n",
    "\n",
    "Below is some code that loads the screenplay for Tarantino's 1994 film 'Pulp Fiction'. I recommend reading through the\n",
    "first 20 lines or so to get a feeling for the language and style used (and enjoy probably the best written screenplay\n",
    "in the history of film)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"PULP FICTION\" -- by Quentin Tarantino & Roger Avary\n",
      "\n",
      "\n",
      "                                      \"PULP FICTION\"\n",
      "\n",
      "                                            By\n",
      "\n",
      "                             Quentin Tarantino & Roger Avary\n",
      "\n",
      "                \n",
      "\n",
      "               PULP [pulp] n.\n",
      "\n",
      "               1. A soft, moist, shapeless mass or matter.\n",
      "\n",
      "               2. A magazine or book containing lurid subject matter and \n",
      "               being characteristically printed on rough, unfinished paper.\n",
      "\n",
      "               American Heritage Dictionary: New College Edition\n",
      "\n",
      "               INT. COFFEE SHOP – MORNING\n",
      "\n",
      "               A normal Denny's, Spires-like coffee shop in Los Angeles. \n",
      "               It's about 9:00 in the morning. While the place isn't jammed, \n",
      "               there's a healthy number of people drinking coffee, munching \n",
      "               on bacon and eating eggs.\n",
      "\n",
      "               Two of these people are a YOUNG MAN and a YOUNG WOMAN. The \n",
      "               Young Man has a slight working-class English accent and, \n",
      "               like his fellow countryman, smokes cigarettes like they're \n",
      "               going out of style.\n",
      "\n",
      "               It is impossible to tell where the Young Woman is from or \n",
      "               how old she is; everything she does contradicts something \n",
      "               she did. The boy and girl sit in a booth. Their dialogue is \n",
      "               to be said in a rapid pace \"HIS GIRL FRIDAY\" fashion.\n",
      "\n",
      "                                     YOUNG MAN\n",
      "                         No, forget it, it's too risky. I'm \n",
      "                         through doin' that shit.\n",
      "\n",
      "                                     YOUNG WOMAN\n",
      "                         You always say that, the same thing \n",
      "                         every time: never again, I'm through, \n",
      "                         too dangerous.\n",
      "\n",
      "                                     YOUNG MAN\n",
      "                         I know that's what I always say. I'm \n",
      "                         always right too, but –\n",
      "\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "response = rq.get(\"http://www.dailyscript.com/scripts/pulp_fiction.html\")\n",
    "text = BeautifulSoup(response.content, \"html.parser\").getText()\n",
    "print(text[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.2.1:** What is the most used symbol in this screenplay and what accuracy would a model constantly predicting this symbol obtain? In other words, what is the \"baseline accuracy\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T20:24:21.624754Z",
     "start_time": "2019-10-14T20:24:21.603763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 164787),\n",
       " ('e', 11513),\n",
       " ('t', 9211),\n",
       " ('o', 8344),\n",
       " ('a', 7713),\n",
       " ('\\n', 7602),\n",
       " ('\\r', 7596),\n",
       " ('n', 7182),\n",
       " ('i', 6751),\n",
       " ('s', 6413)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(text).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T20:25:05.598327Z",
     "start_time": "2019-10-14T20:25:05.574981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.541058693739247"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(text).most_common()[0][1] / len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have adapted some code for text generation from [this Keras example](https://keras.io/examples/lstm_text_generation/), and inserted questions in the code (look for `Q:`) for you to answer in the exercise below.\n",
    "\n",
    "The code fits an LSTM recurrent neural network model to the `text` variable (the Pulp Fiction manuscript). Execute it and see it run. It fits over 50 epochs, so you will probably want to interrupt it (hit `Esc` and then `I` twice) before solving the next exercise though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T21:10:08.952688Z",
     "start_time": "2019-10-14T21:09:02.996574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7614/7614 [==============================] - 7s 932us/step - loss: 2.1535 - categorical_crossentropy: 2.1535 - accuracy: 0.5450\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"arry out the oral \n",
      "               pleas\"\n",
      "arry out the oral \n",
      "               pleas                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"arry out the oral \n",
      "               pleas\"\n",
      "arry out the oral \n",
      "               pleas goe                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"arry out the oral \n",
      "               pleas\"\n",
      "arry out the oral \n",
      "               pleasedisfesttsellbrin     resr! \n",
      "                    ou,                              (rain  houi  fatan gowstrir euns  \n",
      "o terfP wh                                                             u  Voreloddiget ontVAgcnodigle cuarliss kitra-foftppom [ne da  aeto tatiken woud a t d  a  oe t                              fnd bea tu  s                                                                         \n",
      "Epoch 2/50\n",
      "7614/7614 [==============================] - 6s 849us/step - loss: 1.3761 - categorical_crossentropy: 1.3761 - accuracy: 0.6418\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"              up).\n",
      "\n",
      "                  \"\n",
      "              up).\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"              up).\n",
      "\n",
      "                  \"\n",
      "              up).\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"              up).\n",
      "\n",
      "                  \"\n",
      "              up).\n",
      "\n",
      "                                     Vouckang, vazesaNANCEN\n",
      "                        WRTDo PAESCOS shENTG.\n",
      "            A MIONNING NAS OULENThascave peefpankind and aon'lyem.\n",
      "\n",
      "                        Woak ?\n",
      "                       JOwNT\n",
      "                             VINNEXN (ODu – MLACHo biach seon are hit butck facrenCERTAPEOMPMANCAT\n",
      "             Wheatesm, The lperesoin'ad hiin He my on wakk wa cake it?\n",
      "\n",
      "    \n",
      "Epoch 3/50\n",
      "7614/7614 [==============================] - 6s 841us/step - loss: 1.1884 - categorical_crossentropy: 1.1884 - accuracy: 0.6846\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" VINCENT\n",
      "                         What \"\n",
      " VINCENT\n",
      "                         What his his and and and and and and and \n",
      "                                                                                                                                                                                                                                                                                                                                                                          \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" VINCENT\n",
      "                         What \"\n",
      " VINCENT\n",
      "                         What back it \n",
      "                                                                   JULES\n",
      "                                                                                                                                                                                                                                                                                                                            \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" VINCENT\n",
      "                         What \"\n",
      " VINCENT\n",
      "                         What a said.\n",
      "\n",
      "                     Hon amarneciner.\n",
      "\n",
      "                    Ss. TARINE)\n",
      "                            BMARE\n",
      "         TOWYIAS (EDE\n",
      "\n",
      "                    SOMES\n",
      "\n",
      "  RABCECT\n",
      "\n",
      "                         INT. \n",
      "                   aklock upn boM pit'mlucaulesilan youre, \n",
      " 2. WIDIDH\n",
      "\n",
      "           INT\n",
      "W       upellus owtary abient extr this \n",
      "                      That.\n",
      "\n",
      "       Currures i\n",
      "Epoch 4/50\n",
      "7614/7614 [==============================] - 6s 764us/step - loss: 1.0903 - categorical_crossentropy: 1.0903 - accuracy: 0.7087\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"UMPKIN\n",
      "                         I didn'\"\n",
      "UMPKIN\n",
      "                         I didn't got the stard the ding the \n",
      "                                                                                                                                                                                                                                                                                                                                                                                 \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"UMPKIN\n",
      "                         I didn'\"\n",
      "UMPKIN\n",
      "                         I didn't and a dive. It and you and \n",
      "                                                                                                                                                                                                                                                                                                                                                                                 \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"UMPKIN\n",
      "                         I didn'\"\n",
      "UMPKIN\n",
      "                         I didn't IN it a stant.\" in like hie's \n",
      "                      jostid' in her someyin' yef tast. Now tele, yok thindasteat \n",
      "                                             Beptin'.\n",
      "\n",
      "                                        thregu.\n",
      "\n",
      "                   :                  guebisfill tody his OCYYe' moked EXT us stord we \n",
      "                                     goinning.\n",
      "\n",
      "                                   \n",
      "Epoch 5/50\n",
      "7614/7614 [==============================] - 7s 868us/step - loss: 1.0276 - categorical_crossentropy: 1.0276 - accuracy: 0.7236\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"hen being a trapeze artist's \n",
      "         \"\n",
      "hen being a trapeze artist's \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"hen being a trapeze artist's \n",
      "         \"\n",
      "hen being a trapeze artist's \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"hen being a trapeze artist's \n",
      "         \"\n",
      "hen being a trapeze artist's \n",
      "                       strering?\n",
      "\n",
      "               the Sount the CaELART-SP Ma \n",
      "                         Betch me –, some luese ponked, I'm gown the got, \n",
      "                                             MIA\n",
      "                            Vincent)\n",
      "                                           Hew like buppiarm, I don't nowing to wime of her \n",
      "                          Jimmy geas hond shit mach.\n",
      "\n",
      "              \n",
      "Epoch 6/50\n",
      "7614/7614 [==============================] - 7s 876us/step - loss: 0.9818 - categorical_crossentropy: 0.9818 - accuracy: 0.7354\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"INCENT JIMMIE & THE WOLF\"\n",
      "\n",
      "           \"\n",
      "INCENT JIMMIE & THE WOLF\"\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"INCENT JIMMIE & THE WOLF\"\n",
      "\n",
      "           \"\n",
      "INCENT JIMMIE & THE WOLF\"\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"INCENT JIMMIE & THE WOLF\"\n",
      "\n",
      "           \"\n",
      "INCENT JIMMIE & THE WOLF\"\n",
      "\n",
      "                   .45 \n",
      "                       Don'll or to clessed.\n",
      "\n",
      "                                         BUTCH\n",
      "                                                     NDAY OF          Why fullin' boorieses one and you to centorentarione on \n",
      "                                        cat to, lent tarked.\n",
      "\n",
      "                           Vincent and your bocky getne, deap and pleain twe tord \n",
      "              \n",
      "Epoch 7/50\n",
      "7614/7614 [==============================] - 7s 926us/step - loss: 0.9433 - categorical_crossentropy: 0.9433 - accuracy: 0.7450\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" you. It's a great \n",
      "                   \"\n",
      " you. It's a great \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" you. It's a great \n",
      "                   \"\n",
      " you. It's a great \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" you. It's a great \n",
      "                   \"\n",
      " you. It's a great \n",
      "                          Brett a pit... the sweelucerairess.\n",
      "\n",
      "                   FABIENNE\n",
      "                              Bether. Forfie who cartyin' on a sineso.\n",
      "\n",
      "                                    THE WOLE\n",
      "                               THE WOLF\n",
      "                                         Ne, you this your knothings!\n",
      "\n",
      "                         The Young soundyis itsite. But Le's jact-to-taiking to knowar \n",
      "  \n",
      "Epoch 8/50\n",
      "7614/7614 [==============================] - 6s 851us/step - loss: 0.9133 - categorical_crossentropy: 0.9133 - accuracy: 0.7522\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"    to stick their head through that doo\"\n",
      "    to stick their head through that door \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"    to stick their head through that doo\"\n",
      "    to stick their head through that door \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"    to stick their head through that doo\"\n",
      "    to stick their head through that door \n",
      "               tark out to my get let I moundy to Ruie, \n",
      "                            VINCENN\n",
      "                 to mak, kitch suiles that qiary.\n",
      "\n",
      "               out. I'm never a miact out pupkie is \n",
      "                             the bodd fight some oke?\n",
      "\n",
      "                              Fotsers, lookes ad MARAG, to his feer, doirg?\n",
      "\n",
      "                                        LANCE\n",
      "           \n",
      "Epoch 9/50\n",
      "2816/7614 [==========>...................] - ETA: 3s - loss: 0.8879 - categorical_crossentropy: 0.8879 - accuracy: 0.7576"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-1f27024d782c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m           callbacks=[print_callback])\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Q1: What is the purpose of this block? When is `char_indices` used? What about `indices_char`?\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Q2: What is the purpose of this block? What does the `seqlen` and `step` parameters do?\n",
    "seqlen = 40\n",
    "step = seqlen\n",
    "sentences = []\n",
    "for i in range(0, len(text) - seqlen - 1, step):\n",
    "    sentences.append(text[i: i + seqlen + 1])\n",
    "\n",
    "# Q3: What about this block? What is `x` and what is `y`? Why do they have this dimensionality?\n",
    "x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    # Q3a: What happens in this loop?\n",
    "    for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "        x[i, t, char_indices[char_in]] = 1\n",
    "        y[i, t, char_indices[char_out]] = 1\n",
    "\n",
    "\n",
    "# Q4: Here we build the model. What does the `return_sequences` argument do? Why the dense layer at the end?\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "    preds = preds / np.sum(preds)                #\n",
    "    probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "    return np.argmax(probas)                     #\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\"Function invoked at end of each epoch. Prints generated text.\"\"\"\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - seqlen - 1)\n",
    "    \n",
    "    # Q5: What does diversity do?\n",
    "    for diversity in [0.2, 0.5, 1.0]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + seqlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "            \n",
    "            # What is the dimensionality of `preds`? Why do we input `preds[0, -1]` to the `sample` function?\n",
    "            preds = model.predict(x_pred, verbose=0)\n",
    "            next_index = sample(preds[0, -1], diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.2.2**: Add a callback for Tensorboard, so you can log the training process. Start training the network (takes ~10 minutes on my computer). While it's running move on to the next question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.2.3**: Answer the questions in the code above (look for code comments starting with `Q:`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS Q1:** *What is the purpose of this block? When is `char_indices` used? What about `indices_char`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network does not understand letters. Therefore we represent these as one-hot encoded vectors. In this block, we create a mapping between characters and their encoding index. The variables we create are used when we create the input data (text to number encoding), and when we parse the output the network (number to text encoding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS Q2:** *What is the purpose of this block? What does the `seqlen` and `step` parameters do?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are splitting up the data into shorter sequences. The `seqlen` parameter controls the length of these sequences and the `step` controls the overlap between sequences. If `step==seqlen` there is zero overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS Q3:** *What about this block? What is `x` and what is `y`? Why do they have this dimensionality?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are create the input and output data arrays that the network will train on. `x` and `y` has one row for each sentence, and one column for each character in each sentences. Since characters are encoded as one-hot vectors, these extend into the depth dimension. Notice that `y` just contains the \"next-in-line\" characters from `x`. For `seqlen==40` they are therefore 39 columns wide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS Q4:** *Here we build the model. What does the `return_sequences` argument do? Why the dense layer at the end?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`return_sequences` lets us output predictions for every input. The dense layer at the end is to transform the hidden vector that `LSTM` outputs, into a vector which represents our character prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS Q5:** *Q5: What does diversity do?\n",
    "What is the dimensionality of `preds`? Why do we input `preds[0, -1]` to the `sample` function?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diversity controls how evenly distributed the vector, we end up sampling predictions from, is. If diversity is high, we will get very random predictions, and if it is low, we will get very \"predictable\" predictions (usually just the majority letter, often times \"space\"). The dimensionality of `preds` will be (1, 40, 83). We input `preds[0, -1]` when sampling to get a prediction based on our previous prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.2.4**: Did the network finish training? Consider the generated text across epochs.\n",
    "1. In the early batches (0-10), the generated text looks very bad. Can you explain why the low diversity generated text contains almost only the symbol \" \" (that is, spaces)?\n",
    "2. The high diversity generated text is messed up too, but in a different way. Explain how.\n",
    "3. In later batches (20-30) what do you notice is off about the low diversity generated text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowering diversity corresponds to peaking the probability distribution around the most likely value(s), and in this document, the most likely value is space (54% of symbols are spaces). And that is the first thing the network learns. That spaces is the most likely symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing diversity makes draws from the probability distribution very random, so that's why the high-diversity text looks all jumbled. Because it is more or less just random what we end up predicting when we turn up the heat (diversity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later when the model has learned some of the structure in the data, e.g. that after a certain amount of spaces on a newline there should be actual letters, the low-diversity text—rather than repeating the most likely letters—will go one step up the abstraction ladder and simply repeat words or sequences or words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.2.5**: For the network trained over all 50 epochs, generate a longer piece of text\n",
    "(say 5000 symbols long). Use the sentence `text[1486:1526]` as seed (starts with 'YOUNG MAN' ends with 'No, ')\n",
    "and set diversity to 0.5.\n",
    "Describe what features of the screenplay and language in general that the network learned in only 50 epochs.\n",
    "Also describe what serious mistakes it makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T20:44:20.146111Z",
     "start_time": "2019-10-14T20:43:37.362154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"YOUNG MAN\n",
      "                         No, \"\n",
      "YOUNG MAN\n",
      "                         No, YOUNG MAN\n",
      "                         No, YOUNG MAN\n",
      "                         No, YOUNG MAN\n",
      "                         No, YOUNG MAN\n",
      "                         No, how you're gonna give her the sword \n",
      "                         a good to a statte to somethin' is the \n",
      "                         I'll gonna so way, that's your fuckin' \n",
      "                         the balley of the bathroom.\n",
      "\n",
      "                                     JULES\n",
      "                         Well, let's goin' it is.\n",
      "\n",
      "                                     BUTCH\n",
      "                              (jot.\n",
      "\n",
      "                                     VINCENT\n",
      "                         I'll be given a mirally toward I know. I got a \n",
      "                         he gonna saige the way.\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                JULES\n",
      "                         I'm not says: seen him ead is the street when \n",
      "                         that watch towmed in his face.\n",
      "\n",
      "                                     BUTCH\n",
      "                         I don't dagge shake to cup on a big man \n",
      "                         that her eyes something.\n",
      "\n",
      "                                     BUTCH\n",
      "                         I don't want to get my man, I given' \n",
      "                         the same fuckin' fuckin' through the wallets.\n",
      "\n",
      "                                        JULES\n",
      "                         What's her towe to leave in the barse of \n",
      "                         padialophone)\n",
      "                         We won't to you give her table – you're \n",
      "                         the same toor. And I give me to be a \n",
      "                         a little between a bumin' gring. All \n",
      "                         a rag bag is an acrobatch to the bastless as she is \n",
      "                         a good compenting place.\n",
      "\n",
      "                                                                    VINCENT\n",
      "                         Hello I'd be bundy in the kitchent.\n",
      "\n",
      "                                                                                                    VINCENT\n",
      "                         I'm not says: \"yes...\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                          JULES\n",
      "                         Well, and him should wate the same to see-stribe caullivoly.\n",
      "\n",
      "                                     VINCENT\n",
      "                         Well, I git you, don't know what the fuck kiddy.\n",
      "\n",
      "                                     BUTCH\n",
      "                                     JULES\n",
      "                         It's not the door.\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                        JULES\n",
      "                         You coulda just no wall to read.\n",
      "\n",
      "                                     Do make this is the sword to the one, they \n",
      "                         comese of a coffee shit.\n",
      "\n",
      "                                                                                                                    LANCE\n",
      "                         The boys something to his way.\n",
      "\n",
      "                                                                    JULES\n",
      "                         Hello I'm gonna give it is the door. \n",
      "                                                VINCENT\n",
      "                         You did the into bedrob and give half. \n",
      "                                                                                                                                                                      JULES\n",
      "                         I'm a made which MAN, it's like a man, \n",
      "                         now in the grainss to call a little back in \n",
      "                         they time on the mirror first.\n",
      "\n",
      "                                                       \n"
     ]
    }
   ],
   "source": [
    "# generated = ''\n",
    "sentence = text[1486:1526]\n",
    "generated += sentence\n",
    "print('----- Generating with seed: \"' + sentence + '\"')\n",
    "sys.stdout.write(generated)\n",
    "\n",
    "for i in range(5000):\n",
    "    x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    # What is the dimensionality of `preds`? Why do we input `preds[0, -1]` to the `sample` function?\n",
    "    preds = model.predict(x_pred, verbose=0)\n",
    "    next_index = sample(preds[0, -1], 0.5)\n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part it learns the layout style of the screenplay. At a glance it looks alright, but messes up here and there. It makes a lot of formatting errors like opening but never closing quotes, not ending lines on a period, exclamation or question mark, using newlines in the wrong places etc. Finally, of course, the next is nonsense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.2.6**: Do the same as above, but for 40 random letters (e.g. smash away on your keyboard) as seed. What happens? Can you explain why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T20:50:15.882938Z",
     "start_time": "2019-10-14T20:49:44.401581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"lkawuebfuebakvbwlibweibuoubrfuobewfouwyb\"\n",
      "lkawuebfuebakvbwlibweibuoubrfuobewfouwyboull rightenurs his \n",
      "                         a good fillos.\n",
      "\n",
      "                                                JULES\n",
      "                         I think I know, giy nom back in a gingle of \n",
      "                         some floody way. I've gonna give in the \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   MARSELLUS\n",
      "                         Whowe goin' else in the fighten's PLAPS into mirty into a \n",
      "                         the bOO an a taxi react. We pointed to \n",
      "                         a good rise twockle ground man ever balls. \n",
      "                         with me to say into a millions is the \n",
      "                         the offamo to a billeloush offeest to \n",
      "                         comessive.\n",
      "\n",
      "                                     FABIENNE\n",
      "                         What'n' he take the way. I got now.\n",
      "\n",
      "                                     VINCENT\n",
      "                         Well I'm takin' it is the ground)\n",
      "                         What's he was in the other shops of \n",
      "                         the shokes down the fuck a fuck the shot.\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                      BUTCH\n",
      "                         I'm gonna give him back to the bathroom.\n",
      "\n",
      "                                     BUTCH\n",
      "                         Yeah, it's now the fuck up.\n",
      "\n",
      "                                                                                                                                                                                                                                                                                               JULES\n",
      "                         What the fuck as is a shit. The two more ass \n",
      "                         the pance holding down the corner met sound laugh at my \n",
      "                         the same table.\n",
      "\n",
      "                                     BUTCH\n",
      "                         I know how to go in the door. Butch looks up, Jules.\n",
      "\n",
      "                                     VINCENT\n",
      "                         You coulda late the way to comple of the \n",
      "                         you want?\n",
      "                                                                                YOUNG MAN\n",
      "                         Butch pair at the apartment and the money.\n",
      "\n",
      "                                                                                                                    VINCENT\n",
      "                         I'm not says: see is the hole carmin. doin' \n",
      "                         the show behind the holk ass into a book noward to talk in the \n",
      "                         the fuck witce hand something of \n",
      "                         the same table in a good man, I know, Butch to his \n",
      "                         he hands his head: \"yes.\"\n",
      "\n",
      "                                                                                                        MARSELLUS\n",
      "                         Don't be for mading the strill behind his head.\n",
      "\n",
      "                                     VINCENT\n",
      "                         You could leat is to say from his head: \"yes.\"\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                       MARSELLUS\n",
      "                         Yeah.\n",
      "\n",
      "                                     VINCENT\n",
      "                         What's he way.\n",
      "\n",
      "                                                                                                                  BUTCH\n",
      "                         His and starts the wall.\n",
      "\n",
      "                                                                                                                                                           \n"
     ]
    }
   ],
   "source": [
    "generated = ''\n",
    "sentence = \"lkawuebfuebakvbwlibweibuoubrfuobewfouwybefpuyeQBFLSJDVBAEIUPBO48BIUBSEFLIUbwefiuwb\"[:40]\n",
    "generated += sentence\n",
    "print('----- Generating with seed: \"' + sentence + '\"')\n",
    "sys.stdout.write(generated)\n",
    "\n",
    "for i in range(5000):\n",
    "    x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    # What is the dimensionality of `preds`? Why do we input `preds[0, -1]` to the `sample` function?\n",
    "    preds = model.predict(x_pred, verbose=0)\n",
    "    next_index = sample(preds[0, -1], 0.5)\n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, seeding with random text doesn't yield any more randomness in the predicted text. The reason for this is that the network is fully overfitted to the Pulp Fiction manuscript, and since the predictions are fed back into at every timestep, it quickly falls \"back in track\" and starts writing text that is very Pulp Fiction-like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3: Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow [a very nice blog post](https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/) written by Jason Brownlee of 'Machine Learning \n",
    "Mastery' for most of these exercises. In his blog post, Jason takes the reader through\n",
    "the process of using pretrained models in Keras. Below I have outlined the steps you\n",
    "will go through with reference to his blog post. I strongly recommend you read from the\n",
    "top and down to 'Models for Transfer Learning' before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first practical thing we need to figure out when doing transfer learning is loading pretrained models. Keras makes this very easy by offering a number of pretrained models for image classification which can be downloaded through their [Applications API](https://keras.io/applications/#densenet). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applications API arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading pretrained models, we will want to provide some arguments that depend on what\n",
    "we want to do with the model after loading. Below I ask you to explain, in your own words,\n",
    "what some of these parameters do. See the Application API reference on some of the models\n",
    "and the 'Models for Transfer Learning' section in Jason's bloc post for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.3.1**: In your own words, explain what the following function arguments do in\n",
    "the different model loading functions:\n",
    "1. `include_top`\n",
    "1. `weights`\n",
    "1. `input_shape`\n",
    "1. `pooling`\n",
    "1. `classes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether to include the output layer or not. If False, it will output the 1024 dimensional hidden state. This is useful if one needs to use it as a feature extractor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which weights to use. If training from scratch, set it to None (random initialization). If one has own weights, give it a path to the weights. Otherwise set it to 'imagenet' and use the ImageNet weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `include_top` is False, then we can input images of any width and height, as there is no fully connected layer at the end in which the final activation map must fit. So we can specify the shape of our input data in these cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS 4:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `include_top` is False, then we can decide by what strategy the final hidden vector is produced. Basically, how do we want to pool every slice of our final activation map to turn it into a 1d vector (2d in docs because we train in batches)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS 5:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training the network from scratch (i.e. randomly initialized weights) the user can optionally choose to classify any number of targets, not just the default 1000. This option can therefore only be used when `include_top == True` and `weights == None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load a model and predict an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.3.2**: Following Jason's example under 'Pre-Trained Model as Classifier'\n",
    "classify [this image](https://images.squarespace-cdn.com/content/v1/58f0ecc029687fbef7b86b03/1583064484458-IM0UKAZIONS6E2CFCDJC/ke17ZwdGBToddI8pDm48kD5ENJpXCfmjfXuRxqpPb-1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyN2spBBImrH38afc2UL8XBF0s2RHqmX-QW0wG37RpCsIsNysB0CO3b7e86dkNKVNs/Otter+Makes+an+Immediate+U-Turn+Back+to+the+Water.jpg?format=1500w).\n",
    "Print not just the most likely label, but everything that `decode_predictions` returns.\n",
    ">\n",
    "> ***Important***: *Don't use VGG as he does. It's 500 MB to download, and will take too long.\n",
    "> Use one of the smaller models instead ([here](https://keras.io/applications/#documentation-for-individual-models)'s an overview of model sizes), such as DenseNet121.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('n02444819', 'otter', 0.3348522),\n",
       "  ('n02363005', 'beaver', 0.31281713),\n",
       "  ('n02442845', 'mink', 0.09657557),\n",
       "  ('n02396427', 'wild_boar', 0.05625623),\n",
       "  ('n02395406', 'hog', 0.038400274)]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of using a pre-trained model as a classifier\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.densenet import preprocess_input\n",
    "from keras.applications.densenet import decode_predictions\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import Model\n",
    "\n",
    "# load an image from file\n",
    "image = load_img('/Users/ulfaslak/Desktop/Otter+Makes+an+Immediate+U-Turn+Back+to+the+Water.jpg', target_size=(224, 224))\n",
    "\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "# prepare the image for the DenseNet model\n",
    "image = preprocess_input(image)\n",
    "\n",
    "# load the model\n",
    "model = DenseNet121()\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)\n",
    "\n",
    "# convert the probabilities to class labels\n",
    "decode_predictions(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adapting pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple feature extractor for ML prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By removing the last layer, we can turn a pretrained convolutional neural network into a\n",
    "feature extractor. We can then use it to extract features of a large number of images and\n",
    "classify those using any machine learning model. Jason describes this under 'Pre-Trained Model as Feature Extractor Preprocessor'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.3.3:** Extract features for every datapoint in the [fashion-mnist dataset](https://keras.io/datasets/#fashion-mnist-database-of-fashion-articles), and build a feature matrix X. Train an SVM classifier on the learned features, and report the accuracy on the test data.\n",
    ">\n",
    "> *Hint: You can import SVM from sklearn. It has a simply API, just check out some of the examples on the [documentation page](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changing the prediction task (switching out the last layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to achieve roughly the same thing is to remove the last layer and insert a new one with a different number of outputs. Jason describes this under 'Pre-Trained Model as Feature Extractor in Model'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.3.4**: Do the same as above, but by following Jason's example under 'Pre-Trained Model as Feature Extractor in Mode'.\n",
    "Compare to the accuracy you got in 6.2.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you have watched [this video](https://www.youtube.com/watch?v=9zKuYvjFFS8), answer the questions below. I also throw in some questions that link to other sources, to prompt you for a deeper understanding of some of the intuition behind VAEs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.4.1**: What is typically the input and output of an autoencoder? What loss function can be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.4.2**: What is the \"bottleneck\" of an autoencoder? What can it be used for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.4.3**: Purely in terms of architecture, what is the difference between an autoencoder and a variational autoencoder (VAE)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.4.4**: Regular autoencoders are trained to minimize a loss function with no regard to how the latent space is organized. Therefore, continuity is not guaranteed and similar datapoints may not be close to each other. We can thus say that the network is overfitting, because it uses any organization of training points in this space to minimize the loss, and is, therefore, not likely to work well with unseen data. VAEs are a regularized form of autoencoders, invented to solve this problem. Importantly, they guarantee that similar points are close in the latent space. How do they achieve this?\n",
    "    > * How are datapoints represented in the VAE latent space? What is the intuition behind this?\n",
    "    > * How is the loss function different? What is the purpose of the second term (the KL divergence)?\n",
    ">\n",
    "> *Hint: Check out this [blog post](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73) and read the section \"Intuitions about the regularisation\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.4.5**: How is the latent vector sampled from the mean and standard deviation vectors? Explain the \"reparameterization trick\" and why it is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.4.6**: What is the motivation behind the disentangled VAE (or *$\\beta$-VAE*)?\n",
    "What happens is $\\beta$ is too high? What happens when it is too small?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.4.EXTRA**: If you are curious about why such radical generalization\n",
    "performance increases can be achieved by just including a single new hyperparameter\n",
    "in the cost function, check out [the original paper](https://openreview.net/references/pdf?id=Sy2fzU9gl)\n",
    "from Google Deep Mind. In it, under \"$\\beta$-VAE FRAMEWORK DERIVATION\" you will\n",
    "find the intuition behind this small but powerful design modification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.4.7**: Give some examples of what autoencoders can be used for. Creativity allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5: Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you have watched [this video](https://www.youtube.com/watch?v=dCKbRCUyop8), answer the questions below. I also throw in some questions that link to other sources, to prompt you for a deeper understanding of some of the intuition behind GANs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.5.1**: Explain in your own words how the GAN works. Touch upon:\n",
    "    > * What do the generator and discriminator networks do?\n",
    "    > * What are their respective input and output?\n",
    "    > * What would the accuracy of the discriminator be, faced with a perfect generator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.5.2**: What is \"progressive growing\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.5.3**: In StyleGAN, what is the purpose of the mapping network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.5.4**: How do you transform one image to another using backprop and\n",
    "gradient descent? Why does this not always work that well? How is transfer learning\n",
    "used to make it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.5.5**: From [19:20](https://www.youtube.com/watch?v=dCKbRCUyop8&feature=youtu.be&t=1160),\n",
    "outline in bullets the pipeline for obtaining the latent vector for a query image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.5.6**: So why go through all this trouble just to find, basically, the\n",
    "point in the latent space that represents a given image? This gets explained at\n",
    "[22:39](https://youtu.be/dCKbRCUyop8?t=1359). Summarize the idea and utility of\n",
    "labeling the points in the latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.5.7**: Besides modeling faces, can you give some examples of what GANs can be used for?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
